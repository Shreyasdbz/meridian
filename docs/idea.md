<!-- @format -->

# Project Idea: Neuro

## Basics

I want to build "Neuro," an open source AI-powered personal assistant platform that lives on your network (via a low-power device like a Raspberry Pi or Mac mini) and executes tasks of all kinds based on natural language commands completely autonomously, while also learning and improving over time based on web data, successes and failures, and user feedback. The goal is to create a system that can handle a wide variety of tasks, from simple ones like gathering research and managing your calendar, to more complex ones like automating workflows, controlling smart home devices, and even architecting and building entire software projects.

The Neuro platform will be a very thin layer that builds capability based on needs, learnings and user feedback. The core of the platform will be an LLM powered 'Brain' that can understand and execute commands, and a plugin system (the 'Limbs') that allows both the users and the LLM to add capabilities as needed. A runtime, the 'Heart' will be responsible for scheduling and executing tasks, and a 'Memory' system will allow the assistant to remember past interactions and learn from them. The system will be interacted with primarily through natural language with optional voice, images and video attachment capabilities. The interaction service, the 'Skin` will be able to take in inputs via a locally hosted web app that can send text, voice, images and video to the Brain for processing.

### Components Overview

**Runtime**: The runtime is a continuous loop that schedules accepts and schedules jobs. It is non-LLM based, completely deterministic and is responsible for simply picking up a job and triggering it. It is the 'engine' of the system, and is responsible for executing tasks in a timely manner. If the Runtime fails, the entire system fails. The Runtime will be designed to be robust and fault-tolerant, ensuring that tasks are executed reliably and efficiently. Runtime serves as the link between the Brain, Memory, Limbs and Skin, allowing them to work together to execute tasks and learn from interactions over time. Runtime can run jobs in either parallel or sequentially based on the needs of the task and as directed by the Brain, and can also trigger jobs based on time or external events as needed.

**Brain**: The brain is the LLM component of the system. The brain is divided into two parts, the 'Cortex' and the 'Medulla', each completely independent but working together to process commands and execute tasks. The Cortex is responsible for understanding the user's commands, breaking them down into actionable steps, and determining which plugins or capabilities are needed to execute the task. The Medulla, unaware of the user's original command, is responsible for validating the security, privacy, financial, ethical and legal implications of the task, giving feedback to the Cortex on its plan and ultimately approving it only after it has been deemed safe and appropriate to execute. The Cortex will have access to the Neuro Memory, plugins, and the web to execute tasks, while the Medulla will be a secure, highly restricted environment that only has access to the Cortex's proposed plan and system + user instructions / approvals to make its determinations.

**Memory**: The memory system is responsible for distilling ('reflecting') and storing interactions, learnings, successes and failures in a way that allows the system to learn and improve over time. The memory system will be designed to be efficient and scalable, transparent to the user, and will allow the system to remember past interactions and learn from them in a way that improves its performance and capabilities over time.

**Skin**: The skin is responsible for taking in user inputs via a locally hosted web app that can send text, voice, images and video to the Brain for processing. The skin will be designed to be flexible and extensible, allowing for a wide variety of input types and formats, and will be the primary way that users interact with the system. The interface will be one long stream of Neuro and user messages, attachments, and feedback with other tools such as Abort button, status indicators, and logging.

**Limbs**: The limbs are the plugin system of the Neuro platform. They allow both the users and the LLM to add capabilities as needed. The limbs will be designed to be flexible and extensible, allowing for a wide variety of plugins to be developed and integrated into the system, and will be the primary way that the system gains new capabilities over time.

### Mission and Vision

The mission of Neuro is to create a powerful, flexible, and autonomous personal assistant that can help users with a wide variety of tasks, while also learning and improving over time based on user feedback and web data. The vision is to create a system that can handle complex tasks and workflows, while also being safe, ethical, and respectful of user privacy.
Ultimately, the goal is to create a system that can help users be more productive, efficient, and creative in their personal and professional lives. Each Neuro is specialized to its user, and over time becomes more attuned, capable and responsible to that user's needs, preferences and values, while also being able to learn from the broader web and other users' experiences in a way that allows it to improve and adapt over time.
Neuro will work completely autonomously in the background until a task is completed or user attention is needed, at which point it will notify the user and ask for feedback on how it did, allowing it to learn and improve over time. It is designed to keep learning and improving by performing web research to figure out how to do new tasks, and by reflecting on its successes and failures and distilling learnings from them in a way that allows it to perform better in the future. The system will be designed to be safe, ethical, and respectful of user privacy, with the Medulla serving as a check on the Cortex's plans to ensure that they are appropriate and safe to execute.
Neuro can be deployed in a private VPS or on a local low-power device like a Raspberry Pi or Mac mini, ensuring that user data remains private and secure. It can also be extended with local LLMs on a more powerful machine if desired via Ollama or similar frameworks. Otherwise, it uses API keys provided by the user to connect to LLM services of their choice like Anthropic, OpenAI, Google, etc. The Brain and Medulla models can be selected independently based on the user's needs and preferences.

### Potential Use Cases

**Personal Productivity**: Neuro can help users manage their calendars, set reminders, draft emails, and automate routine tasks, allowing them to focus on more important work.
**Research and Information Gathering**: Neuro can gather information from the web, summarize articles, and provide insights on a wide variety of topics, making it a valuable tool for students, professionals, and lifelong learners.
**Smart Home Automation**: Neuro can integrate with smart home devices to automate routines, control lighting and temperature, and enhance home security without having to use the device-specific apps.
**Software Development**: Neuro can assist with coding tasks, debug issues, and even help architect and build entire software projects based on high-level descriptions from the user completely autonomously, while also learning and improving over time based on successes, failures and user feedback.
**Creative Projects**: Neuro can assist with creative tasks like writing, graphic design, and video editing, providing suggestions and automating repetitive tasks to help users bring their ideas to life.
**Research and Data Analysis**: Neuro can help users gather and analyze data, generate reports, and visualize insights, making it a valuable tool for researchers and data scientists.
